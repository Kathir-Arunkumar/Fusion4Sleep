{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cabd692-ff68-434a-93ac-41d9677b787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59b1c9b-2c9a-4f7b-8f2a-05a1726c3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_eeg_file_path = \"normal_eeg.csv\"\n",
    "normal_ecg_file_path = \"normal_ecg.csv\"\n",
    "normal_eog_file_path = \"normal_eog.csv\"\n",
    "normal_emg_file_path = \"normal_emg.csv\"\n",
    "\n",
    "insomniac_eeg_file_path = \"insomnia_eeg.csv\"\n",
    "insomniac_ecg_file_path = \"insomnia_ecg.csv\"\n",
    "insomniac_eog_file_path = \"insomnia_eog.csv\"\n",
    "insomniac_emg_file_path = \"insomnia_emg.csv\"\n",
    "\n",
    "# Load data from each file and label each as normal or insomniac\n",
    "def load_and_label_data(eeg_file, ecg_file, eog_file, emg_file, condition_label):\n",
    "    eeg_df = pd.read_csv(eeg_file)\n",
    "    ecg_df = pd.read_csv(ecg_file)\n",
    "    eog_df = pd.read_csv(eog_file)\n",
    "    emg_df = pd.read_csv(emg_file)\n",
    "    \n",
    "    # Combine all features into a single DataFrame\n",
    "    combined_df = pd.concat([eeg_df, ecg_df, eog_df, emg_df], axis=1)\n",
    "    combined_df['Condition'] = condition_label  # Add condition label\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d512dcd-1c7e-4ffd-9a92-9742492d042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and label normal and insomniac data\n",
    "normal_data = load_and_label_data(normal_eeg_file_path, normal_ecg_file_path, normal_eog_file_path, normal_emg_file_path, 0)  # Label 0 for Normal\n",
    "insomniac_data = load_and_label_data(insomniac_eeg_file_path, insomniac_ecg_file_path, insomniac_eog_file_path, insomniac_emg_file_path, 1)  # Label 1 for Insomniac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28caced4-ab84-41ff-acb4-d0504c5efee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([normal_data, insomniac_data], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "data = shuffle(data, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d552032a-dd36-4f6c-894c-d585fea47037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Condition'])\n",
    "y = data['Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e884b63-af1a-473a-88bf-359f96c499f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb2a167-d9a2-44a9-a374-73f41bfd234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = {\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'MLP Classifier': MLPClassifier(random_state=42, max_iter=1000),\n",
    "    'Extra Trees': ExtraTreesClassifier(random_state=42),\n",
    "    'SGD Classifier': SGDClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec097574-a3c4-43da-9318-9cc19a01814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.63\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69      1276\n",
      "           1       0.71      0.42      0.53      1262\n",
      "\n",
      "    accuracy                           0.63      2538\n",
      "   macro avg       0.65      0.63      0.61      2538\n",
      "weighted avg       0.65      0.63      0.61      2538\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.95\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      1276\n",
      "           1       0.93      0.96      0.95      1262\n",
      "\n",
      "    accuracy                           0.95      2538\n",
      "   macro avg       0.95      0.95      0.95      2538\n",
      "weighted avg       0.95      0.95      0.95      2538\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.88\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88      1276\n",
      "           1       0.86      0.92      0.89      1262\n",
      "\n",
      "    accuracy                           0.88      2538\n",
      "   macro avg       0.88      0.88      0.88      2538\n",
      "weighted avg       0.88      0.88      0.88      2538\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.74\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74      1276\n",
      "           1       0.73      0.74      0.74      1262\n",
      "\n",
      "    accuracy                           0.74      2538\n",
      "   macro avg       0.74      0.74      0.74      2538\n",
      "weighted avg       0.74      0.74      0.74      2538\n",
      "\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.79\n",
      "\n",
      "K-Nearest Neighbors Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79      1276\n",
      "           1       0.78      0.81      0.79      1262\n",
      "\n",
      "    accuracy                           0.79      2538\n",
      "   macro avg       0.79      0.79      0.79      2538\n",
      "weighted avg       0.79      0.79      0.79      2538\n",
      "\n",
      "\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.79\n",
      "\n",
      "AdaBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1276\n",
      "           1       0.79      0.79      0.79      1262\n",
      "\n",
      "    accuracy                           0.79      2538\n",
      "   macro avg       0.79      0.79      0.79      2538\n",
      "weighted avg       0.79      0.79      0.79      2538\n",
      "\n",
      "\n",
      "Training MLP Classifier...\n",
      "MLP Classifier Accuracy: 0.74\n",
      "\n",
      "MLP Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      1276\n",
      "           1       0.76      0.70      0.73      1262\n",
      "\n",
      "    accuracy                           0.74      2538\n",
      "   macro avg       0.74      0.74      0.74      2538\n",
      "weighted avg       0.74      0.74      0.74      2538\n",
      "\n",
      "\n",
      "Training Extra Trees...\n",
      "Extra Trees Accuracy: 0.95\n",
      "\n",
      "Extra Trees Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1276\n",
      "           1       0.93      0.98      0.95      1262\n",
      "\n",
      "    accuracy                           0.95      2538\n",
      "   macro avg       0.95      0.95      0.95      2538\n",
      "weighted avg       0.95      0.95      0.95      2538\n",
      "\n",
      "\n",
      "Training SGD Classifier...\n",
      "SGD Classifier Accuracy: 0.70\n",
      "\n",
      "SGD Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69      1276\n",
      "           1       0.69      0.71      0.70      1262\n",
      "\n",
      "    accuracy                           0.70      2538\n",
      "   macro avg       0.70      0.70      0.70      2538\n",
      "weighted avg       0.70      0.70      0.70      2538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in model_list.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"\\n{model_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6148e05f-b3f1-4f00-997a-0a5e070b3dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.91\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      1276\n",
      "           1       0.88      0.94      0.91      1262\n",
      "\n",
      "    accuracy                           0.91      2538\n",
      "   macro avg       0.91      0.91      0.91      2538\n",
      "weighted avg       0.91      0.91      0.91      2538\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.95\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1276\n",
      "           1       0.94      0.97      0.95      1262\n",
      "\n",
      "    accuracy                           0.95      2538\n",
      "   macro avg       0.95      0.95      0.95      2538\n",
      "weighted avg       0.95      0.95      0.95      2538\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.89\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89      1276\n",
      "           1       0.88      0.91      0.89      1262\n",
      "\n",
      "    accuracy                           0.89      2538\n",
      "   macro avg       0.89      0.89      0.89      2538\n",
      "weighted avg       0.89      0.89      0.89      2538\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.77\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1276\n",
      "           1       0.77      0.77      0.77      1262\n",
      "\n",
      "    accuracy                           0.77      2538\n",
      "   macro avg       0.77      0.77      0.77      2538\n",
      "weighted avg       0.77      0.77      0.77      2538\n",
      "\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.93\n",
      "\n",
      "K-Nearest Neighbors Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      1276\n",
      "           1       0.91      0.94      0.93      1262\n",
      "\n",
      "    accuracy                           0.93      2538\n",
      "   macro avg       0.93      0.93      0.93      2538\n",
      "weighted avg       0.93      0.93      0.93      2538\n",
      "\n",
      "\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.80\n",
      "\n",
      "AdaBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1276\n",
      "           1       0.80      0.80      0.80      1262\n",
      "\n",
      "    accuracy                           0.80      2538\n",
      "   macro avg       0.80      0.80      0.80      2538\n",
      "weighted avg       0.80      0.80      0.80      2538\n",
      "\n",
      "\n",
      "Training MLP Classifier...\n",
      "MLP Classifier Accuracy: 0.95\n",
      "\n",
      "MLP Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1276\n",
      "           1       0.95      0.95      0.95      1262\n",
      "\n",
      "    accuracy                           0.95      2538\n",
      "   macro avg       0.95      0.95      0.95      2538\n",
      "weighted avg       0.95      0.95      0.95      2538\n",
      "\n",
      "\n",
      "Training Extra Trees...\n",
      "Extra Trees Accuracy: 0.95\n",
      "\n",
      "Extra Trees Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1276\n",
      "           1       0.93      0.97      0.95      1262\n",
      "\n",
      "    accuracy                           0.95      2538\n",
      "   macro avg       0.95      0.95      0.95      2538\n",
      "weighted avg       0.95      0.95      0.95      2538\n",
      "\n",
      "\n",
      "Training SGD Classifier...\n",
      "SGD Classifier Accuracy: 0.77\n",
      "\n",
      "SGD Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1276\n",
      "           1       0.77      0.76      0.77      1262\n",
      "\n",
      "    accuracy                           0.77      2538\n",
      "   macro avg       0.77      0.77      0.77      2538\n",
      "weighted avg       0.77      0.77      0.77      2538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "normal_eeg_file_path = \"normal_eeg.csv\"\n",
    "normal_ecg_file_path = \"normal_ecg.csv\"\n",
    "normal_eog_file_path = \"normal_eog.csv\"\n",
    "normal_emg_file_path = \"normal_emg.csv\"\n",
    "\n",
    "insomniac_eeg_file_path = \"insomnia_eeg.csv\"\n",
    "insomniac_ecg_file_path = \"insomnia_ecg.csv\"\n",
    "insomniac_eog_file_path = \"insomnia_eog.csv\"\n",
    "insomniac_emg_file_path = \"insomnia_emg.csv\"\n",
    "\n",
    "# Load data from each file and label each as normal or insomniac\n",
    "def load_and_label_data(eeg_file, ecg_file, eog_file, emg_file, condition_label):\n",
    "    eeg_df = pd.read_csv(eeg_file)\n",
    "    ecg_df = pd.read_csv(ecg_file)\n",
    "    eog_df = pd.read_csv(eog_file)\n",
    "    emg_df = pd.read_csv(emg_file)\n",
    "    \n",
    "    # Combine all features into a single DataFrame\n",
    "    combined_df = pd.concat([eeg_df, ecg_df, eog_df, emg_df], axis=1)\n",
    "    combined_df['Condition'] = condition_label  # Add condition label\n",
    "    return combined_df\n",
    "\n",
    "# Load and label normal and insomniac data\n",
    "normal_data = load_and_label_data(normal_eeg_file_path, normal_ecg_file_path, normal_eog_file_path, normal_emg_file_path, 0)  # Label 0 for Normal\n",
    "insomniac_data = load_and_label_data(insomniac_eeg_file_path, insomniac_ecg_file_path, insomniac_eog_file_path, insomniac_emg_file_path, 1)  # Label 1 for Insomniac\n",
    "\n",
    "data = pd.concat([normal_data, insomniac_data], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "data = shuffle(data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = data.drop(columns=['Condition'])\n",
    "y = data['Condition']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_list = {\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'MLP Classifier': MLPClassifier(random_state=42, max_iter=1000),\n",
    "    'Extra Trees': ExtraTreesClassifier(random_state=42),\n",
    "    'SGD Classifier': SGDClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in model_list.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"\\n{model_name} Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Note:\n",
    "# - The features have been normalized using StandardScaler before training the models to improve their performance.\n",
    "# - This normalization ensures that all features have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f6141-b9c6-4652-8ee4-0d06a3f5bed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
